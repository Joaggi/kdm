{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 1\tMuscle loss\n",
    "- 2\t2-Oxoglutarate\n",
    "- 3\t3-Aminoisobutyrate\n",
    "- 4\tAdipate\n",
    "- 5\tBetaine\n",
    "- 6\tCreatinine\n",
    "- 7\tHypoxanthine\n",
    "- 8\tN,N-Dimethylglycine\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- 1\t3\n",
    "- 1\t4\n",
    "- 1\t5\n",
    "- 1\t7\n",
    "- 2\t7\n",
    "- 6\t7\n",
    "- 8\t5\n",
    "\n",
    "\n",
    "Directed GRAPH of the example - Comparison Accuracy 0.7532"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kdm.models import KDMSequentialJointClassModel\n",
    "import kdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_moons\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from keras import metrics\n",
    "from keras import losses\n",
    "from keras import optimizers\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense\n",
    "import keras\n",
    "from pandas import read_csv, DataFrame\n",
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_csv('cachexia.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient ID</th>\n",
       "      <th>Muscle loss</th>\n",
       "      <th>1,6-Anhydro-beta-D-glucose</th>\n",
       "      <th>1-Methylnicotinamide</th>\n",
       "      <th>2-Aminobutyrate</th>\n",
       "      <th>2-Hydroxyisobutyrate</th>\n",
       "      <th>2-Oxoglutarate</th>\n",
       "      <th>3-Aminoisobutyrate</th>\n",
       "      <th>3-Hydroxybutyrate</th>\n",
       "      <th>3-Hydroxyisovalerate</th>\n",
       "      <th>...</th>\n",
       "      <th>Tryptophan</th>\n",
       "      <th>Tyrosine</th>\n",
       "      <th>Uracil</th>\n",
       "      <th>Valine</th>\n",
       "      <th>Xylose</th>\n",
       "      <th>cis-Aconitate</th>\n",
       "      <th>myo-Inositol</th>\n",
       "      <th>trans-Aconitate</th>\n",
       "      <th>pi-Methylhistidine</th>\n",
       "      <th>tau-Methylhistidine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PIF_178</td>\n",
       "      <td>cachexic</td>\n",
       "      <td>40.85</td>\n",
       "      <td>65.37</td>\n",
       "      <td>18.73</td>\n",
       "      <td>26.05</td>\n",
       "      <td>71.52</td>\n",
       "      <td>1480.30</td>\n",
       "      <td>56.83</td>\n",
       "      <td>10.07</td>\n",
       "      <td>...</td>\n",
       "      <td>259.82</td>\n",
       "      <td>290.03</td>\n",
       "      <td>111.05</td>\n",
       "      <td>86.49</td>\n",
       "      <td>72.24</td>\n",
       "      <td>237.46</td>\n",
       "      <td>135.64</td>\n",
       "      <td>51.94</td>\n",
       "      <td>157.59</td>\n",
       "      <td>160.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PIF_087</td>\n",
       "      <td>cachexic</td>\n",
       "      <td>62.18</td>\n",
       "      <td>340.36</td>\n",
       "      <td>24.29</td>\n",
       "      <td>41.68</td>\n",
       "      <td>67.36</td>\n",
       "      <td>116.75</td>\n",
       "      <td>43.82</td>\n",
       "      <td>79.84</td>\n",
       "      <td>...</td>\n",
       "      <td>83.10</td>\n",
       "      <td>167.34</td>\n",
       "      <td>46.99</td>\n",
       "      <td>109.95</td>\n",
       "      <td>192.48</td>\n",
       "      <td>333.62</td>\n",
       "      <td>376.15</td>\n",
       "      <td>217.02</td>\n",
       "      <td>307.97</td>\n",
       "      <td>130.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PIF_090</td>\n",
       "      <td>cachexic</td>\n",
       "      <td>270.43</td>\n",
       "      <td>64.72</td>\n",
       "      <td>12.18</td>\n",
       "      <td>65.37</td>\n",
       "      <td>23.81</td>\n",
       "      <td>14.30</td>\n",
       "      <td>5.64</td>\n",
       "      <td>23.34</td>\n",
       "      <td>...</td>\n",
       "      <td>82.27</td>\n",
       "      <td>60.34</td>\n",
       "      <td>31.50</td>\n",
       "      <td>59.15</td>\n",
       "      <td>2164.62</td>\n",
       "      <td>330.30</td>\n",
       "      <td>86.49</td>\n",
       "      <td>58.56</td>\n",
       "      <td>145.47</td>\n",
       "      <td>83.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NETL_005_V1</td>\n",
       "      <td>cachexic</td>\n",
       "      <td>154.47</td>\n",
       "      <td>52.98</td>\n",
       "      <td>172.43</td>\n",
       "      <td>74.44</td>\n",
       "      <td>1199.91</td>\n",
       "      <td>555.57</td>\n",
       "      <td>175.91</td>\n",
       "      <td>25.03</td>\n",
       "      <td>...</td>\n",
       "      <td>235.10</td>\n",
       "      <td>323.76</td>\n",
       "      <td>30.57</td>\n",
       "      <td>102.51</td>\n",
       "      <td>125.21</td>\n",
       "      <td>1863.11</td>\n",
       "      <td>247.15</td>\n",
       "      <td>75.94</td>\n",
       "      <td>249.64</td>\n",
       "      <td>254.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PIF_115</td>\n",
       "      <td>cachexic</td>\n",
       "      <td>22.20</td>\n",
       "      <td>73.70</td>\n",
       "      <td>15.64</td>\n",
       "      <td>83.93</td>\n",
       "      <td>33.12</td>\n",
       "      <td>29.67</td>\n",
       "      <td>76.71</td>\n",
       "      <td>69.41</td>\n",
       "      <td>...</td>\n",
       "      <td>103.54</td>\n",
       "      <td>142.59</td>\n",
       "      <td>44.26</td>\n",
       "      <td>160.77</td>\n",
       "      <td>186.79</td>\n",
       "      <td>101.49</td>\n",
       "      <td>749.95</td>\n",
       "      <td>98.49</td>\n",
       "      <td>84.77</td>\n",
       "      <td>79.84</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Patient ID Muscle loss  1,6-Anhydro-beta-D-glucose  1-Methylnicotinamide  \\\n",
       "0      PIF_178    cachexic                       40.85                 65.37   \n",
       "1      PIF_087    cachexic                       62.18                340.36   \n",
       "2      PIF_090    cachexic                      270.43                 64.72   \n",
       "3  NETL_005_V1    cachexic                      154.47                 52.98   \n",
       "4      PIF_115    cachexic                       22.20                 73.70   \n",
       "\n",
       "   2-Aminobutyrate  2-Hydroxyisobutyrate  2-Oxoglutarate  3-Aminoisobutyrate  \\\n",
       "0            18.73                 26.05           71.52             1480.30   \n",
       "1            24.29                 41.68           67.36              116.75   \n",
       "2            12.18                 65.37           23.81               14.30   \n",
       "3           172.43                 74.44         1199.91              555.57   \n",
       "4            15.64                 83.93           33.12               29.67   \n",
       "\n",
       "   3-Hydroxybutyrate  3-Hydroxyisovalerate  ...  Tryptophan  Tyrosine  Uracil  \\\n",
       "0              56.83                 10.07  ...      259.82    290.03  111.05   \n",
       "1              43.82                 79.84  ...       83.10    167.34   46.99   \n",
       "2               5.64                 23.34  ...       82.27     60.34   31.50   \n",
       "3             175.91                 25.03  ...      235.10    323.76   30.57   \n",
       "4              76.71                 69.41  ...      103.54    142.59   44.26   \n",
       "\n",
       "   Valine   Xylose  cis-Aconitate  myo-Inositol  trans-Aconitate  \\\n",
       "0   86.49    72.24         237.46        135.64            51.94   \n",
       "1  109.95   192.48         333.62        376.15           217.02   \n",
       "2   59.15  2164.62         330.30         86.49            58.56   \n",
       "3  102.51   125.21        1863.11        247.15            75.94   \n",
       "4  160.77   186.79         101.49        749.95            98.49   \n",
       "\n",
       "   pi-Methylhistidine  tau-Methylhistidine  \n",
       "0              157.59               160.77  \n",
       "1              307.97               130.32  \n",
       "2              145.47                83.93  \n",
       "3              249.64               254.68  \n",
       "4               84.77                79.84  \n",
       "\n",
       "[5 rows x 65 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finish just Muscle loss, 3-Aminoisobutyrate, Adipate, Betaine and Hypoxanthine\n",
    "\n",
    "filtered_df = df[['Muscle loss', '3-Aminoisobutyrate', 'Adipate', 'Betaine', 'Hypoxanthine']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Muscle loss</th>\n",
       "      <th>3-Aminoisobutyrate</th>\n",
       "      <th>Adipate</th>\n",
       "      <th>Betaine</th>\n",
       "      <th>Hypoxanthine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cachexic</td>\n",
       "      <td>1480.30</td>\n",
       "      <td>38.09</td>\n",
       "      <td>109.95</td>\n",
       "      <td>97.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cachexic</td>\n",
       "      <td>116.75</td>\n",
       "      <td>327.01</td>\n",
       "      <td>244.69</td>\n",
       "      <td>82.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cachexic</td>\n",
       "      <td>14.30</td>\n",
       "      <td>131.63</td>\n",
       "      <td>116.75</td>\n",
       "      <td>114.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cachexic</td>\n",
       "      <td>555.57</td>\n",
       "      <td>144.03</td>\n",
       "      <td>278.66</td>\n",
       "      <td>223.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cachexic</td>\n",
       "      <td>29.67</td>\n",
       "      <td>15.03</td>\n",
       "      <td>391.51</td>\n",
       "      <td>66.69</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Muscle loss  3-Aminoisobutyrate  Adipate  Betaine  Hypoxanthine\n",
       "0    cachexic             1480.30    38.09   109.95         97.51\n",
       "1    cachexic              116.75   327.01   244.69         82.27\n",
       "2    cachexic               14.30   131.63   116.75        114.43\n",
       "3    cachexic              555.57   144.03   278.66        223.63\n",
       "4    cachexic               29.67    15.03   391.51         66.69"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2s/yq898nms72b5qxqbwz_hx8j80000gn/T/ipykernel_73525/903024324.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['Muscle loss'] = filtered_df['Muscle loss'].apply(lambda x: 1 if x == 'cachexic' else 0)\n"
     ]
    }
   ],
   "source": [
    "# transform musche loss in 0-1\n",
    "filtered_df['Muscle loss'] = filtered_df['Muscle loss'].apply(lambda x: 1 if x == 'cachexic' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Muscle loss</th>\n",
       "      <th>3-Aminoisobutyrate</th>\n",
       "      <th>Adipate</th>\n",
       "      <th>Betaine</th>\n",
       "      <th>Hypoxanthine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1480.30</td>\n",
       "      <td>38.09</td>\n",
       "      <td>109.95</td>\n",
       "      <td>97.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>116.75</td>\n",
       "      <td>327.01</td>\n",
       "      <td>244.69</td>\n",
       "      <td>82.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>14.30</td>\n",
       "      <td>131.63</td>\n",
       "      <td>116.75</td>\n",
       "      <td>114.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>555.57</td>\n",
       "      <td>144.03</td>\n",
       "      <td>278.66</td>\n",
       "      <td>223.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>29.67</td>\n",
       "      <td>15.03</td>\n",
       "      <td>391.51</td>\n",
       "      <td>66.69</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Muscle loss  3-Aminoisobutyrate  Adipate  Betaine  Hypoxanthine\n",
       "0            1             1480.30    38.09   109.95         97.51\n",
       "1            1              116.75   327.01   244.69         82.27\n",
       "2            1               14.30   131.63   116.75        114.43\n",
       "3            1              555.57   144.03   278.66        223.63\n",
       "4            1               29.67    15.03   391.51         66.69"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction Power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "encoded_size = 4\n",
    "dim_y = 2\n",
    "encoder = keras.layers.Identity()\n",
    "n_comp = 77\n",
    "sequences = [\n",
    "    {\n",
    "        'type': 'merge'\n",
    "    },\n",
    "    ]\n",
    "kdm_model = KDMSequentialJointClassModel(encoded_size=encoded_size,\n",
    "                                         dim_y=dim_y,\n",
    "                                         encoder=encoder,\n",
    "                                         n_comp=n_comp,\n",
    "                                         sequences=sequences,\n",
    "                                         sigma=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "kdm_model.compile(optimizer=optimizers.Adam(learning_rate=5e-5),\n",
    "                  loss=losses.sparse_categorical_crossentropy,\n",
    "                  metrics=[metrics.sparse_categorical_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for row in filtered_df.iterrows():\n",
    "    y = int(row[1]['Muscle loss'])\n",
    "    x = row[1][1:].values\n",
    "    data.append((x, y))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = np.array([x for x, y in data])\n",
    "y_out = np.array([y for x, y in data])\n",
    "output = np.array([[0,1] if y == 1 else [1,0] for x, y in data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "kdm_model.init_components(np.array(input), np.array(output),\n",
    "                                init_sigma=True, sigma_mult=0.5, super_index=0, index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4964 - sparse_categorical_accuracy: 0.8037  \n"
     ]
    }
   ],
   "source": [
    "check_1 = kdm_model.evaluate(np.array(input), np.array(y_out))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Dataset loss: 0.5318797826766968\n",
      "Full Dataset accuracy: 0.7792207598686218\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('Full Dataset loss:', check_1[0])\n",
    "print('Full Dataset accuracy:', check_1[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2s/yq898nms72b5qxqbwz_hx8j80000gn/T/ipykernel_73525/3391731745.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  combined_y = np.array([[y, [0,1]] if y == 1 else [y, [1,0]] for x, y in data])\n"
     ]
    }
   ],
   "source": [
    "combined_y = np.array([[y, [0,1]] if y == 1 else [y, [1,0]] for x, y in data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    input, combined_y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "encoded_size = 4\n",
    "dim_y = 2\n",
    "encoder = keras.layers.Identity()\n",
    "n_comp = 69\n",
    "sequences = [\n",
    "    {\n",
    "        'type': 'merge'\n",
    "    },\n",
    "    ]\n",
    "kdm_model = KDMSequentialJointClassModel(encoded_size=encoded_size,\n",
    "                                         dim_y=dim_y,\n",
    "                                         encoder=encoder,\n",
    "                                         n_comp=n_comp,\n",
    "                                         sequences=sequences,\n",
    "                                         sigma=0.5)\n",
    "\n",
    "kdm_model.compile(optimizer=optimizers.Adam(learning_rate=5e-7),\n",
    "                  loss=losses.sparse_categorical_crossentropy,\n",
    "                  metrics=[metrics.sparse_categorical_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, list([1, 0])],\n",
       "       [1, list([0, 1])],\n",
       "       [0, list([1, 0])],\n",
       "       [0, list([1, 0])],\n",
       "       [1, list([0, 1])],\n",
       "       [1, list([0, 1])],\n",
       "       [0, list([1, 0])],\n",
       "       [1, list([0, 1])],\n",
       "       [1, list([0, 1])],\n",
       "       [1, list([0, 1])],\n",
       "       [1, list([0, 1])],\n",
       "       [1, list([0, 1])],\n",
       "       [1, list([0, 1])],\n",
       "       [1, list([0, 1])],\n",
       "       [1, list([0, 1])],\n",
       "       [1, list([0, 1])],\n",
       "       [0, list([1, 0])],\n",
       "       [0, list([1, 0])],\n",
       "       [1, list([0, 1])],\n",
       "       [1, list([0, 1])],\n",
       "       [0, list([1, 0])],\n",
       "       [1, list([0, 1])],\n",
       "       [0, list([1, 0])],\n",
       "       [0, list([1, 0])],\n",
       "       [0, list([1, 0])],\n",
       "       [1, list([0, 1])],\n",
       "       [0, list([1, 0])],\n",
       "       [1, list([0, 1])],\n",
       "       [1, list([0, 1])],\n",
       "       [1, list([0, 1])],\n",
       "       [0, list([1, 0])],\n",
       "       [1, list([0, 1])],\n",
       "       [1, list([0, 1])],\n",
       "       [1, list([0, 1])],\n",
       "       [1, list([0, 1])],\n",
       "       [0, list([1, 0])],\n",
       "       [1, list([0, 1])],\n",
       "       [1, list([0, 1])],\n",
       "       [0, list([1, 0])],\n",
       "       [0, list([1, 0])],\n",
       "       [1, list([0, 1])],\n",
       "       [0, list([1, 0])],\n",
       "       [1, list([0, 1])],\n",
       "       [1, list([0, 1])],\n",
       "       [1, list([0, 1])],\n",
       "       [1, list([0, 1])],\n",
       "       [0, list([1, 0])],\n",
       "       [1, list([0, 1])],\n",
       "       [1, list([0, 1])],\n",
       "       [0, list([1, 0])],\n",
       "       [0, list([1, 0])],\n",
       "       [1, list([0, 1])],\n",
       "       [1, list([0, 1])],\n",
       "       [0, list([1, 0])],\n",
       "       [0, list([1, 0])],\n",
       "       [0, list([1, 0])],\n",
       "       [0, list([1, 0])],\n",
       "       [1, list([0, 1])],\n",
       "       [1, list([0, 1])],\n",
       "       [1, list([0, 1])],\n",
       "       [0, list([1, 0])],\n",
       "       [1, list([0, 1])],\n",
       "       [1, list([0, 1])],\n",
       "       [1, list([0, 1])],\n",
       "       [1, list([0, 1])],\n",
       "       [0, list([1, 0])],\n",
       "       [0, list([1, 0])],\n",
       "       [1, list([0, 1])],\n",
       "       [0, list([1, 0])]], dtype=object)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_out = np.array([y[1] for y in y_train])\n",
    "\n",
    "kdm_model.init_components(np.array(X_train), np.array(real_out),\n",
    "                                init_sigma=True, sigma_mult=0.5, super_index=0, index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4766 - sparse_categorical_accuracy: 0.7841  \n"
     ]
    }
   ],
   "source": [
    "check_full = kdm_model.evaluate(np.array(input), np.array(y_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Dataset loss: 0.5080514550209045\n",
      "Full Dataset accuracy: 0.7792207598686218\n"
     ]
    }
   ],
   "source": [
    "print('Full Dataset loss:', check_full[0])\n",
    "print('Full Dataset accuracy:', check_full[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.6675 - sparse_categorical_accuracy: 0.5000\n"
     ]
    }
   ],
   "source": [
    "check_test = kdm_model.evaluate(np.array(X_test), np.array([y[0] for y in y_test]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.6674742698669434\n",
      "Test accuracy: 0.5\n"
     ]
    }
   ],
   "source": [
    "print('Test loss:', check_test[0])\n",
    "print('Test accuracy:', check_test[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.7910 - sparse_categorical_accuracy: 0.4282 - val_loss: 0.9639 - val_sparse_categorical_accuracy: 0.5714\n",
      "Epoch 2/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 996us/step - loss: 0.8959 - sparse_categorical_accuracy: 0.4450 - val_loss: 0.9645 - val_sparse_categorical_accuracy: 0.5714\n",
      "Epoch 3/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 983us/step - loss: 0.8723 - sparse_categorical_accuracy: 0.5460 - val_loss: 0.9650 - val_sparse_categorical_accuracy: 0.5714\n",
      "Epoch 4/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 753us/step - loss: 1.0666 - sparse_categorical_accuracy: 0.5410 - val_loss: 0.9656 - val_sparse_categorical_accuracy: 0.5714\n",
      "Epoch 5/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 744us/step - loss: 1.2113 - sparse_categorical_accuracy: 0.5678 - val_loss: 0.9661 - val_sparse_categorical_accuracy: 0.5714\n",
      "Epoch 6/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 758us/step - loss: 0.8881 - sparse_categorical_accuracy: 0.6009 - val_loss: 0.9668 - val_sparse_categorical_accuracy: 0.5714\n",
      "Epoch 7/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 768us/step - loss: 0.8659 - sparse_categorical_accuracy: 0.5620 - val_loss: 0.9673 - val_sparse_categorical_accuracy: 0.5714\n",
      "Epoch 8/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 886us/step - loss: 1.0379 - sparse_categorical_accuracy: 0.5344 - val_loss: 0.9678 - val_sparse_categorical_accuracy: 0.5714\n",
      "Epoch 9/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 855us/step - loss: 0.9642 - sparse_categorical_accuracy: 0.5197 - val_loss: 0.9684 - val_sparse_categorical_accuracy: 0.5714\n",
      "Epoch 10/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 837us/step - loss: 0.8999 - sparse_categorical_accuracy: 0.5432 - val_loss: 0.9690 - val_sparse_categorical_accuracy: 0.5714\n",
      "Epoch 11/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 872us/step - loss: 1.0227 - sparse_categorical_accuracy: 0.5542 - val_loss: 0.9695 - val_sparse_categorical_accuracy: 0.5714\n",
      "Epoch 12/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 840us/step - loss: 0.9408 - sparse_categorical_accuracy: 0.4964 - val_loss: 0.9701 - val_sparse_categorical_accuracy: 0.5714\n",
      "Epoch 13/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 857us/step - loss: 1.1090 - sparse_categorical_accuracy: 0.4662 - val_loss: 0.9707 - val_sparse_categorical_accuracy: 0.5714\n",
      "Epoch 14/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 892us/step - loss: 1.4377 - sparse_categorical_accuracy: 0.4449 - val_loss: 0.9713 - val_sparse_categorical_accuracy: 0.5714\n",
      "Epoch 15/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 817us/step - loss: 1.2572 - sparse_categorical_accuracy: 0.5533 - val_loss: 0.9718 - val_sparse_categorical_accuracy: 0.5714\n",
      "Epoch 16/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 873us/step - loss: 0.8727 - sparse_categorical_accuracy: 0.5048 - val_loss: 0.9724 - val_sparse_categorical_accuracy: 0.5714\n",
      "Epoch 17/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803us/step - loss: 1.0617 - sparse_categorical_accuracy: 0.4603 - val_loss: 0.9730 - val_sparse_categorical_accuracy: 0.5714\n",
      "Epoch 18/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 787us/step - loss: 1.1865 - sparse_categorical_accuracy: 0.5500 - val_loss: 0.9736 - val_sparse_categorical_accuracy: 0.5714\n",
      "Epoch 19/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 809us/step - loss: 1.0441 - sparse_categorical_accuracy: 0.5285 - val_loss: 0.9742 - val_sparse_categorical_accuracy: 0.5714\n",
      "Epoch 20/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 774us/step - loss: 0.9207 - sparse_categorical_accuracy: 0.5473 - val_loss: 0.9747 - val_sparse_categorical_accuracy: 0.5714\n",
      "Epoch 21/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 840us/step - loss: 1.1245 - sparse_categorical_accuracy: 0.5045 - val_loss: 0.9753 - val_sparse_categorical_accuracy: 0.5714\n",
      "Epoch 22/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step - loss: 0.8681 - sparse_categorical_accuracy: 0.5535 - val_loss: 0.9758 - val_sparse_categorical_accuracy: 0.5714\n",
      "Epoch 23/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 816us/step - loss: 1.1928 - sparse_categorical_accuracy: 0.4483 - val_loss: 0.9765 - val_sparse_categorical_accuracy: 0.5714\n",
      "Epoch 24/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 808us/step - loss: 1.3039 - sparse_categorical_accuracy: 0.3409 - val_loss: 0.9770 - val_sparse_categorical_accuracy: 0.5714\n",
      "Epoch 25/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 788us/step - loss: 1.1036 - sparse_categorical_accuracy: 0.5179 - val_loss: 0.9776 - val_sparse_categorical_accuracy: 0.5714\n",
      "Epoch 26/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 768us/step - loss: 0.9633 - sparse_categorical_accuracy: 0.6087 - val_loss: 0.9782 - val_sparse_categorical_accuracy: 0.5714\n",
      "Epoch 27/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 776us/step - loss: 1.2009 - sparse_categorical_accuracy: 0.4281 - val_loss: 0.9787 - val_sparse_categorical_accuracy: 0.5714\n",
      "Epoch 28/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.0016 - sparse_categorical_accuracy: 0.5779 - val_loss: 0.9793 - val_sparse_categorical_accuracy: 0.5714\n",
      "Epoch 29/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827us/step - loss: 1.5260 - sparse_categorical_accuracy: 0.4247 - val_loss: 0.9799 - val_sparse_categorical_accuracy: 0.5714\n",
      "Epoch 30/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 0.8549 - sparse_categorical_accuracy: 0.4808 - val_loss: 0.9805 - val_sparse_categorical_accuracy: 0.5714\n",
      "Epoch 31/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 740us/step - loss: 0.9091 - sparse_categorical_accuracy: 0.5152 - val_loss: 0.9809 - val_sparse_categorical_accuracy: 0.5714\n",
      "Epoch 32/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 760us/step - loss: 0.9847 - sparse_categorical_accuracy: 0.5525 - val_loss: 0.9816 - val_sparse_categorical_accuracy: 0.5714\n",
      "Epoch 33/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 745us/step - loss: 1.3115 - sparse_categorical_accuracy: 0.5060 - val_loss: 0.9822 - val_sparse_categorical_accuracy: 0.5714\n",
      "Epoch 34/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 730us/step - loss: 0.8773 - sparse_categorical_accuracy: 0.5814 - val_loss: 0.9827 - val_sparse_categorical_accuracy: 0.5714\n",
      "Epoch 35/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9831 - sparse_categorical_accuracy: 0.5017 - val_loss: 0.9834 - val_sparse_categorical_accuracy: 0.5714\n",
      "Epoch 36/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0069 - sparse_categorical_accuracy: 0.4788 - val_loss: 0.9839 - val_sparse_categorical_accuracy: 0.5714\n",
      "Epoch 37/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 848us/step - loss: 1.3614 - sparse_categorical_accuracy: 0.4688 - val_loss: 0.9845 - val_sparse_categorical_accuracy: 0.5714\n",
      "Epoch 38/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 741us/step - loss: 1.1565 - sparse_categorical_accuracy: 0.4864 - val_loss: 0.9850 - val_sparse_categorical_accuracy: 0.5714\n",
      "Epoch 39/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 735us/step - loss: 0.9659 - sparse_categorical_accuracy: 0.5177 - val_loss: 0.9856 - val_sparse_categorical_accuracy: 0.5714\n",
      "Epoch 40/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 707us/step - loss: 0.7791 - sparse_categorical_accuracy: 0.6264 - val_loss: 0.9861 - val_sparse_categorical_accuracy: 0.4286\n",
      "Epoch 41/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 742us/step - loss: 0.8158 - sparse_categorical_accuracy: 0.4612 - val_loss: 0.9868 - val_sparse_categorical_accuracy: 0.4286\n",
      "Epoch 42/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 771us/step - loss: 0.7888 - sparse_categorical_accuracy: 0.4959 - val_loss: 0.9873 - val_sparse_categorical_accuracy: 0.4286\n",
      "Epoch 43/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 813us/step - loss: 0.7298 - sparse_categorical_accuracy: 0.5664 - val_loss: 0.9879 - val_sparse_categorical_accuracy: 0.4286\n",
      "Epoch 44/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 750us/step - loss: 0.9203 - sparse_categorical_accuracy: 0.5670 - val_loss: 0.9884 - val_sparse_categorical_accuracy: 0.4286\n",
      "Epoch 45/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803us/step - loss: 0.8141 - sparse_categorical_accuracy: 0.4897 - val_loss: 0.9891 - val_sparse_categorical_accuracy: 0.4286\n",
      "Epoch 46/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 791us/step - loss: 0.7915 - sparse_categorical_accuracy: 0.5396 - val_loss: 0.9895 - val_sparse_categorical_accuracy: 0.4286\n",
      "Epoch 47/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 765us/step - loss: 0.7875 - sparse_categorical_accuracy: 0.5402 - val_loss: 0.9902 - val_sparse_categorical_accuracy: 0.4286\n",
      "Epoch 48/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 778us/step - loss: 0.9603 - sparse_categorical_accuracy: 0.6253 - val_loss: 0.9907 - val_sparse_categorical_accuracy: 0.4286\n",
      "Epoch 49/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 752us/step - loss: 1.0275 - sparse_categorical_accuracy: 0.5598 - val_loss: 0.9913 - val_sparse_categorical_accuracy: 0.4286\n",
      "Epoch 50/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 742us/step - loss: 1.5284 - sparse_categorical_accuracy: 0.4806 - val_loss: 0.9918 - val_sparse_categorical_accuracy: 0.4286\n",
      "Epoch 51/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 742us/step - loss: 0.7465 - sparse_categorical_accuracy: 0.6043 - val_loss: 0.9924 - val_sparse_categorical_accuracy: 0.4286\n",
      "Epoch 52/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 761us/step - loss: 1.1824 - sparse_categorical_accuracy: 0.5081 - val_loss: 0.9929 - val_sparse_categorical_accuracy: 0.4286\n",
      "Epoch 53/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 739us/step - loss: 1.0311 - sparse_categorical_accuracy: 0.5235 - val_loss: 0.9935 - val_sparse_categorical_accuracy: 0.4286\n",
      "Epoch 54/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 759us/step - loss: 0.7217 - sparse_categorical_accuracy: 0.5064 - val_loss: 0.9941 - val_sparse_categorical_accuracy: 0.4286\n",
      "Epoch 55/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 719us/step - loss: 1.1819 - sparse_categorical_accuracy: 0.5683 - val_loss: 0.9947 - val_sparse_categorical_accuracy: 0.4286\n",
      "Epoch 56/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 758us/step - loss: 1.0834 - sparse_categorical_accuracy: 0.5107 - val_loss: 0.9952 - val_sparse_categorical_accuracy: 0.4286\n",
      "Epoch 57/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 735us/step - loss: 0.9947 - sparse_categorical_accuracy: 0.5202 - val_loss: 0.9958 - val_sparse_categorical_accuracy: 0.4286\n",
      "Epoch 58/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 748us/step - loss: 0.7352 - sparse_categorical_accuracy: 0.5655 - val_loss: 0.9964 - val_sparse_categorical_accuracy: 0.4286\n",
      "Epoch 59/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1.1007 - sparse_categorical_accuracy: 0.5034 - val_loss: 0.9969 - val_sparse_categorical_accuracy: 0.4286\n",
      "Epoch 60/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 833us/step - loss: 1.0319 - sparse_categorical_accuracy: 0.4779 - val_loss: 0.9975 - val_sparse_categorical_accuracy: 0.4286\n",
      "Epoch 61/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 787us/step - loss: 1.0950 - sparse_categorical_accuracy: 0.5405 - val_loss: 0.9980 - val_sparse_categorical_accuracy: 0.4286\n",
      "Epoch 62/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 748us/step - loss: 1.1179 - sparse_categorical_accuracy: 0.5799 - val_loss: 0.9986 - val_sparse_categorical_accuracy: 0.4286\n",
      "Epoch 63/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 710us/step - loss: 1.2587 - sparse_categorical_accuracy: 0.4818 - val_loss: 0.9992 - val_sparse_categorical_accuracy: 0.4286\n",
      "Epoch 64/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 718us/step - loss: 1.0470 - sparse_categorical_accuracy: 0.5525 - val_loss: 0.9997 - val_sparse_categorical_accuracy: 0.4286\n",
      "Epoch 65/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 734us/step - loss: 0.7292 - sparse_categorical_accuracy: 0.5424 - val_loss: 1.0003 - val_sparse_categorical_accuracy: 0.4286\n",
      "Epoch 66/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 752us/step - loss: 1.0402 - sparse_categorical_accuracy: 0.5148 - val_loss: 1.0009 - val_sparse_categorical_accuracy: 0.4286\n",
      "Epoch 67/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 733us/step - loss: 1.2340 - sparse_categorical_accuracy: 0.5843 - val_loss: 1.0014 - val_sparse_categorical_accuracy: 0.4286\n",
      "Epoch 68/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 748us/step - loss: 1.1077 - sparse_categorical_accuracy: 0.5490 - val_loss: 1.0020 - val_sparse_categorical_accuracy: 0.4286\n",
      "Epoch 69/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 733us/step - loss: 1.1028 - sparse_categorical_accuracy: 0.4545 - val_loss: 1.0026 - val_sparse_categorical_accuracy: 0.4286\n",
      "Epoch 70/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 757us/step - loss: 0.7986 - sparse_categorical_accuracy: 0.6224 - val_loss: 1.0031 - val_sparse_categorical_accuracy: 0.4286\n",
      "Epoch 71/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 750us/step - loss: 1.3003 - sparse_categorical_accuracy: 0.4946 - val_loss: 1.0037 - val_sparse_categorical_accuracy: 0.4286\n",
      "Epoch 72/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 714us/step - loss: 1.1989 - sparse_categorical_accuracy: 0.4929 - val_loss: 1.0043 - val_sparse_categorical_accuracy: 0.4286\n",
      "Epoch 73/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 734us/step - loss: 0.9804 - sparse_categorical_accuracy: 0.5151 - val_loss: 1.0048 - val_sparse_categorical_accuracy: 0.4286\n",
      "Epoch 74/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 849us/step - loss: 0.9822 - sparse_categorical_accuracy: 0.5084 - val_loss: 1.0054 - val_sparse_categorical_accuracy: 0.4286\n",
      "Epoch 75/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 736us/step - loss: 0.9595 - sparse_categorical_accuracy: 0.4986 - val_loss: 1.0060 - val_sparse_categorical_accuracy: 0.4286\n",
      "Epoch 76/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 693us/step - loss: 1.0602 - sparse_categorical_accuracy: 0.5222 - val_loss: 1.0065 - val_sparse_categorical_accuracy: 0.4286\n",
      "Epoch 77/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 715us/step - loss: 1.3767 - sparse_categorical_accuracy: 0.4197 - val_loss: 1.0070 - val_sparse_categorical_accuracy: 0.4286\n",
      "Epoch 78/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 711us/step - loss: 0.9778 - sparse_categorical_accuracy: 0.4839 - val_loss: 1.0077 - val_sparse_categorical_accuracy: 0.4286\n",
      "Epoch 79/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 728us/step - loss: 1.1108 - sparse_categorical_accuracy: 0.5872 - val_loss: 1.0082 - val_sparse_categorical_accuracy: 0.4286\n",
      "Epoch 80/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 736us/step - loss: 1.2441 - sparse_categorical_accuracy: 0.5383 - val_loss: 1.0088 - val_sparse_categorical_accuracy: 0.4286\n",
      "Epoch 81/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 729us/step - loss: 0.8014 - sparse_categorical_accuracy: 0.4902 - val_loss: 1.0094 - val_sparse_categorical_accuracy: 0.4286\n",
      "Epoch 82/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 705us/step - loss: 0.8878 - sparse_categorical_accuracy: 0.5672 - val_loss: 1.0099 - val_sparse_categorical_accuracy: 0.4286\n",
      "Epoch 83/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 727us/step - loss: 1.2355 - sparse_categorical_accuracy: 0.4862 - val_loss: 1.0104 - val_sparse_categorical_accuracy: 0.4286\n",
      "Epoch 84/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 735us/step - loss: 1.3964 - sparse_categorical_accuracy: 0.4899 - val_loss: 1.0110 - val_sparse_categorical_accuracy: 0.4286\n",
      "Epoch 85/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 703us/step - loss: 1.2336 - sparse_categorical_accuracy: 0.5036 - val_loss: 1.0115 - val_sparse_categorical_accuracy: 0.4286\n",
      "Epoch 86/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 725us/step - loss: 1.0650 - sparse_categorical_accuracy: 0.5807 - val_loss: 1.0121 - val_sparse_categorical_accuracy: 0.4286\n",
      "Epoch 87/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.8479 - sparse_categorical_accuracy: 0.6473 - val_loss: 1.0128 - val_sparse_categorical_accuracy: 0.4286\n",
      "Epoch 88/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step - loss: 0.8958 - sparse_categorical_accuracy: 0.5435 - val_loss: 1.0133 - val_sparse_categorical_accuracy: 0.4286\n",
      "Epoch 89/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 705us/step - loss: 1.1012 - sparse_categorical_accuracy: 0.5565 - val_loss: 1.0139 - val_sparse_categorical_accuracy: 0.4286\n",
      "Epoch 90/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 724us/step - loss: 0.8926 - sparse_categorical_accuracy: 0.5431 - val_loss: 1.0144 - val_sparse_categorical_accuracy: 0.4286\n",
      "Epoch 91/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 714us/step - loss: 1.3022 - sparse_categorical_accuracy: 0.5285 - val_loss: 1.0150 - val_sparse_categorical_accuracy: 0.4286\n",
      "Epoch 92/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 716us/step - loss: 0.9344 - sparse_categorical_accuracy: 0.4769 - val_loss: 1.0156 - val_sparse_categorical_accuracy: 0.4286\n",
      "Epoch 93/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 733us/step - loss: 1.0379 - sparse_categorical_accuracy: 0.5546 - val_loss: 1.0162 - val_sparse_categorical_accuracy: 0.4286\n",
      "Epoch 94/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 730us/step - loss: 1.0536 - sparse_categorical_accuracy: 0.5185 - val_loss: 1.0167 - val_sparse_categorical_accuracy: 0.4286\n",
      "Epoch 95/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 709us/step - loss: 1.1126 - sparse_categorical_accuracy: 0.4874 - val_loss: 1.0172 - val_sparse_categorical_accuracy: 0.4286\n",
      "Epoch 96/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 738us/step - loss: 0.8476 - sparse_categorical_accuracy: 0.5209 - val_loss: 1.0178 - val_sparse_categorical_accuracy: 0.4286\n",
      "Epoch 97/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 727us/step - loss: 0.8199 - sparse_categorical_accuracy: 0.5474 - val_loss: 1.0184 - val_sparse_categorical_accuracy: 0.4286\n",
      "Epoch 98/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 725us/step - loss: 0.8770 - sparse_categorical_accuracy: 0.5206 - val_loss: 1.0189 - val_sparse_categorical_accuracy: 0.4286\n",
      "Epoch 99/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 717us/step - loss: 0.8591 - sparse_categorical_accuracy: 0.6092 - val_loss: 1.0195 - val_sparse_categorical_accuracy: 0.4286\n",
      "Epoch 100/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 816us/step - loss: 0.9683 - sparse_categorical_accuracy: 0.5141 - val_loss: 1.0200 - val_sparse_categorical_accuracy: 0.4286\n"
     ]
    }
   ],
   "source": [
    "history = kdm_model.fit(\n",
    "    np.array(X_train),  # Your training data\n",
    "    np.array(y_out),  # Your training labels\n",
    "    batch_size=2,\n",
    "    epochs=100, \n",
    "    verbose=1,  # Detailed logging\n",
    "    validation_split=0.1,  # Explicit validation data\n",
    "    shuffle=True  # Shuffle the data\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4680 - sparse_categorical_accuracy: 0.8180 \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.6800 - sparse_categorical_accuracy: 0.6250\n"
     ]
    }
   ],
   "source": [
    "\n",
    "check_full = kdm_model.evaluate(np.array(input), np.array(y_out))\n",
    "check_test = kdm_model.evaluate(np.array(X_test), np.array([y[0] for y in y_test]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Dataset loss: 0.5098720192909241\n",
      "Full Dataset accuracy: 0.7922077775001526\n",
      "Test loss: 0.6799858808517456\n",
      "Test accuracy: 0.625\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('Full Dataset loss:', check_full[0])\n",
    "print('Full Dataset accuracy:', check_full[1])\n",
    "\n",
    "\n",
    "print('Test loss:', check_test[0])\n",
    "print('Test accuracy:', check_test[1])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
